{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0f2f6a-1845-46f9-86e0-a551492e89ca",
   "metadata": {},
   "source": [
    "# Get started with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1c9837-42f8-4796-b7aa-959baed9e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ed0178-be55-4ffd-ba07-836e1fe527c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478bba21-d3bc-4472-b25b-5e1e4711a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3966885b-25de-4c97-b599-cd064556d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28), name='layers_input'),\n",
    "    tf.keras.layers.Flatten(name='layers_flatten'),\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n",
    "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c267f-1694-4954-82d7-17fd9a498494",
   "metadata": {},
   "source": [
    "# Using TensorBoard with Keras Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a6c003-c8c7-4ec6-9e0c-8c0b75262d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3557 - val_accuracy: 0.9692 - val_loss: 0.1006\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1017 - val_accuracy: 0.9763 - val_loss: 0.0805\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0687 - val_accuracy: 0.9771 - val_loss: 0.0713\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0539 - val_accuracy: 0.9791 - val_loss: 0.0661\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0398 - val_accuracy: 0.9791 - val_loss: 0.0704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13eb6d5ab10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f8ac8f-5102-4bc2-b3c2-042b90f55c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cf99e8605d06258b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cf99e8605d06258b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3adb4-98e9-4d0e-95e8-57fce2b9de96",
   "metadata": {},
   "source": [
    "# Using TensorBoard with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509c77af-1f9a-4ef0-a743-014860939fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(60000).batch(64)\n",
    "test_dataset = test_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d83812-6670-4984-8025-1c53bccf298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1f4a12-b424-4528-9fc8-b08020a800f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our metrics\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c3acc6-1c60-4c8e-90c7-e4d114397f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_train, y_train):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(x_train, training=True)\n",
    "    loss = loss_object(y_train, predictions)\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y_train, predictions)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "  predictions = model(x_test)\n",
    "  loss = loss_object(y_test, predictions)\n",
    "\n",
    "  test_loss(loss)\n",
    "  test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b8af7e7-ee82-46a5-aef3-a9ceb8c21ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957454f1-e3ea-4347-8cd1-9692d7fe67f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24900002777576447, Accuracy: 92.72000122070312, Test Loss: 0.11587978899478912, Test Accuracy: 96.55000305175781\n",
      "Epoch 2, Loss: 0.10515713691711426, Accuracy: 96.86833953857422, Test Loss: 0.08457132428884506, Test Accuracy: 97.40999603271484\n",
      "Epoch 3, Loss: 0.07332859188318253, Accuracy: 97.8183364868164, Test Loss: 0.07063847035169601, Test Accuracy: 97.83999633789062\n",
      "Epoch 4, Loss: 0.05496705323457718, Accuracy: 98.36166381835938, Test Loss: 0.06381893157958984, Test Accuracy: 98.1199951171875\n",
      "Epoch 5, Loss: 0.04481379687786102, Accuracy: 98.62166595458984, Test Loss: 0.059351254254579544, Test Accuracy: 98.18999481201172\n"
     ]
    }
   ],
   "source": [
    "model = create_model() # reset our model\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for (x_train, y_train) in train_dataset:\n",
    "    train_step(model, optimizer, x_train, y_train)\n",
    "  with train_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "  for (x_test, y_test) in test_dataset:\n",
    "    test_step(model, x_test, y_test)\n",
    "  with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "  \n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(), \n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(), \n",
    "                         test_accuracy.result()*100))\n",
    "\n",
    "  # Reset metrics every epoch\n",
    "  train_loss.reset_state()\n",
    "  test_loss.reset_state()\n",
    "  train_accuracy.reset_state()\n",
    "  test_accuracy.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea3cda-6dda-488a-b866-66bd7dd526c3",
   "metadata": {},
   "source": [
    "Open TensorBoard again, this time pointing it at the new log directory. We could have also started TensorBoard to monitor training while it progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ddfa25-d3be-489c-a000-85fac325da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9baf1cb6c859b270\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9baf1cb6c859b270\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132b688-4393-46fb-9d21-0e1d6384df30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
